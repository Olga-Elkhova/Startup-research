# Исследование динамики и структуры финансирования стартапов

Проект исследования стартапов для выявления перспективных компаний для перепродажи.
**Цели проекта:**
Исследовать финансирование стартапов. Выделить критерии по которым можно оценить привлекательность стартапа для его покупки и перепродажи.

## Шаг 1. Знакомство с данными: загрузка и первичная предобработка
### 1.1 Загрузка данных
 
**Названия файлов:**
* acquisition.csv
* company_and_rounds.csv
* degrees.csv
* education.csv
* fund.csv
* investment.csv
* people.csv
 
**Импортируем библиотеки**

```
import pandas as pd

# Загружаем библиотеки для визуализации данных**

import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns

#Загружаем библиотеку для расчёта коэффициента корреляции phi_k**

try:
    import phik
except ModuleNotFoundError as e:
    get_ipython().system('pip install phik')
    import phik
    print("Error was:", e) # Это позволит установить необходимую библиотеку в случае её отсутствия
```

**Выведем информацию о датафреймах**

Создаем датафреймы из предоставленных таблиц
Записывем базовую часть в переменную 
```
base_url = "https://code.s3....."

# Создаем датафремы с использованием переменной
company_and_rounds = pd.read_csv(base_url + 'company_and_rounds.csv')
acquisition = pd.read_csv(base_url + 'acquisition.csv')
degrees = pd.read_csv(base_url + 'degrees.csv')
education = pd.read_csv(base_url + 'education.csv')
fund = pd.read_csv(base_url + 'fund.csv')
investment = pd.read_csv(base_url + 'investment.csv')
people = pd.read_csv(base_url + 'people.csv')
```
**Приведем к единому стилю написания названий столбцов**
```
# Переименуем столбец company  ID
company_and_rounds = company_and_rounds.rename(columns={'company  ID': 'id'})

# Приведем столбцы в company_and_rounds к стилю snake case
company_and_rounds.columns = company_and_rounds.columns.str.replace('  ','_')

# Выведем названия столбцов после изменений
company_and_rounds.columns

# Создаем список названий файлов
filenames = ['company_and_rounds.csv', 'acquisition.csv', 'degrees.csv', 'education.csv', 'fund.csv', 'investment.csv', 'people.csv']

# Создаем список датафреймов
dfs = {file: pd.read_csv(base_url + file) for file in filenames}
```
**Выведем информацию о датафреймах**
```
def lookup_datasets(dfs, filenames=None):
    """
    Выводит информацию о датасетах из списка

    Parameters:
        dfs (list of pd.DataFrame): Список датафреймов для обработки.
        filenames (list of str): Список названий файлов (имена для отображения).
    """
    if filenames is None:
        filenames = [f"df_{i + 1}" for i in range(len(dfs))]

    for df, df_name in zip(dfs, filenames):
        print('-'*10,' '*5, df_name, ' '*5, '-'*10)

        # Пропущенные значения
        missing_data = df.isna().mean()
        missing_data_result = missing_data.apply(lambda x: f'{x:.2%}' if x > 0 else "")
        missing_data_name = "Пропущено" if missing_data.sum() > 0 else ""
        missing_data_result.name = missing_data_name

        # Типы данных
        dtypes_result = df.dtypes
        dtypes_result.name = "Тип данных колонки"
        fewest_nans_row = df.iloc[1:-1].isna().sum(axis=1).idxmin()

        values_type = df.loc[fewest_nans_row].map(type).T
        values_type.name = "Тип значения"

        # Объединяем результаты и пример данных
        result = pd.concat([
            dtypes_result, # типы
            values_type, # типы значений
            missing_data_result, # пропущенные значения
            df.iloc[0, :], # первая строка
            df.loc[fewest_nans_row].T, # полная строка
            df.iloc[-1, :] # последняя строка
        ], axis=1)

        display(result)

        # Проверка на полные дубликаты
        duplicates = df.duplicated().mean()
        if duplicates > 0:
            print(f'Полных дубликатов: {duplicates:.2%}')

        print()
```
**Проводим автоматический осмотр данных**
```
column_counts = lookup_datasets(dfs.values(), dfs.keys())
```
![Датафреймы_1](https://github.com/Olga-Elkhova/Startup-research/blob/main/Датафреймы_1.png)
![Датафреймы_2](https://github.com/Olga-Elkhova/Startup-research/blob/main/Датафреймы_2.png)
![Датафреймы_3](https://github.com/Olga-Elkhova/Startup-research/blob/main/Датафреймы_3.png)

**В датафрейме `company_and_rounds` содержится информация о компаниях и раундах финансирования.**
- всего 217774 строк, 22 столбца
- 12 столбцов с типом данных float64
- 10 столбцов с типом данных object. В столбце founded_at содержится дата финансирования, тип данных некорректен 
- пропуски есть во всех столбцах
 
Названия столбцов соответствуют содержанию. Есть столбцы с идентичным названием, но с разным содержанием `company_ID` и `company_id`. Чтобы избежать ошибок при одинаковом имени столбцов, столбец `company_ID` переименован в `id`.

Столбцы `is_first_round` и `is_last_round` показывают наличие у клиента того или иного признака и содержат значения `1` или `0`.

**В датафрейме `acquisition` содержится информация о покупках одними компаниями других компаний.**
- всего 9407 строк, 6 столбцов
- 4 столбца с типом данных int64
- 2 столбца с типом данных object. В столбце acquired_at содержится дата финансирования, тип данных некорректен.
- пропуски есть в двух столбцах
- названия столбцов соответствуют содержанию.

**В датафрейме `degrees` содержится информация о типе образования сотрудника.**

- всего 109610 строк, 4 столбца
- 1 столбец с типом данных int64
- 3 столбца с типом данных object
- пропуски есть в двух столбцах
- названия столбцов соответствуют содержанию.

**В датафрейме `education` содержится информация о покупках одними компаниями других компаний.**

- всего 109610 строк, 4 столбца
- 1 столбец с типом данных int64
- 3 столбца с типом данных object.  В столбце graduated_at содержится дата получения образования, тип данных некорректен.
- пропуски есть в двух столбцах
- названия столбцов соответствуют содержанию.

**В датафрейме `fund` содержится информация о фондах.**

- всего 11652 строк, 9 столбцов
- 4 столбца с типом данных int64
- 5 столбцов с типом данных object
- пропуски есть в пяти столбцах
- названия столбцов соответствуют содержанию.

**В датафрейме `investment` содержится информация о раундах инвестирования.**

- всего 6140 строк, 4 столбца
- 4 столбца с типом данных int64
- пропусков нет
- названия столбцов соответствуют содержанию.

**В датафрейме `people` содержится информация о сотрудниках.**
 
- всего 226709 строк, 5 столбцов
- 1 столбец с типом данных float64
- 1 столбец с типом данных int64
- 3 столбца с типом данных object
- пропуски есть в четырех столбцах
- названия столбцов соответствуют содержанию.
 
### 1.2 Смена типов данных и анализ пропусков
 
В датафреймах company_and_rounds, acquisition, education, fund в столбцах с типом object содержится дата и время.
Для столбцов, содержащих дату и время изменим тип данных на datetime64

**Меняем тип данных в датафрейме company_and_rounds**
```
company_and_rounds[['founded_at', 'closed_at', 'funded_at']] = company_and_rounds[['founded_at', 'closed_at', 'funded_at']].astype('datetime64[ns]')
```
Для удобства анализа по годам. выделим из столбцов с датами года
```
company_and_rounds[['founded_year', 'closed_year', 'funded_year']] = company_and_rounds[['founded_at', 'closed_at', 'funded_at']].apply(lambda x: x.dt.year)
```
**Выведем несколько строк датафрейма с новыми столбцами**
```
company_and_rounds.head()
```
**Меняем тип данных в датафрейме acquisition**
```
acquisition['acquired_at'] = acquisition['acquired_at'].astype('datetime64[ns]')
```
**Выводим информацию о датафрейме с новым типом данных**
```
acquisition.info()
```

**Меняем тип данных в датафрейме education**
```
education['graduated_at'] = education['graduated_at'].astype('datetime64[ns]')
```
**Выводим информацию о датафрейме с новым типом данных**
```
education.info()
```
**Меняем тип данных в датафрейме fund**
```
fund['founded_at'] = fund['founded_at'].astype('datetime64[ns]')
```
**Выводим информацию о датафрейме с новым типом данных**
```
fund.info()
```
Типы данных изменены на корректные.
Удалим из датафремов явные дубликаты, если они есть.

**Убираем явные дубликаты в company_and_rounds**
```
company_and_rounds.drop_duplicates()
```

**Убираем явные дубликаты в acquisition**
```
acquisition.drop_duplicates()
```

**Убираем явные дубликаты в people**
```
people.drop_duplicates()
```
**Убираем явные дубликаты в degrees**
```
degrees.drop_duplicates()
```
**Убираем явные дубликаты в education**
```
education.drop_duplicates()
```
**Убираем явные дубликаты в fund**
```
fund.drop_duplicates()
```
**Убираем явные дубликаты в investment**
```
investment.drop_duplicates()
```
Количество строк во всех датафреймах не изменилось. Явных дубликатов нет.

На этапе знакомства с данными были выявлены пропуски во многих столбцах. Для дальнейшей работы нужно определить их долю в датафреймах, чтобы понять, можно ли их удалить.

**Посчитаем долю пропусков в столбце company_and_rounds**
```
pd.DataFrame(round(company_and_rounds.isna().mean()*100, 2)).sort_values(by=0, ascending=False).style.background_gradient('coolwarm')
```
![Пропуски_company_and_rounds](https://github.com/Olga-Elkhova/Startup-research/blob/main/Пропуски_company_and_rounds.png)
**Посчитаем долю пропусков в датафрейме acquisition**
```
pd.DataFrame(round(acquisition.isna().mean()*100, 2)).sort_values(by=0, ascending=False).style.background_gradient('coolwarm')
```
![Пропуски_acquisition](https://github.com/Olga-Elkhova/Startup-research/blob/main/Пропуски_acquisition.png)
**Посчитаем долю пропусков в датафрейме education**
```
pd.DataFrame(round(education.isna().mean()*100, 2)).sort_values(by=0, ascending=False).style.background_gradient('coolwarm')
```
![Пропуски_education](https://github.com/Olga-Elkhova/Startup-research/blob/main/Пропуски_education.png)
**Посчитаем долю пропусков в датафрейме people**
```
pd.DataFrame(round(people.isna().mean()*100, 2)).sort_values(by=0, ascending=False).style.background_gradient('coolwarm')
```
![Пропуски_people](https://github.com/Olga-Elkhova/Startup-research/blob/main/Пропуски_people.png)
**Посчитаем долю пропусков в датафрейме degrees**
```
pd.DataFrame(round(degrees.isna().mean()*100, 2)).sort_values(by=0, ascending=False).style.background_gradient('coolwarm')
```
![Пропуски_degrees](https://github.com/Olga-Elkhova/Startup-research/blob/main/Пропуски_degrees.png)
**Посчитаем долю пропусков в датафрейме fund**
```
pd.DataFrame(round(fund.isna().mean()*100, 2)).sort_values(by=0, ascending=False).style.background_gradient('coolwarm')
```
![Пропуски_fund](https://github.com/Olga-Elkhova/Startup-research/blob/main/Пропуски_fund.png)
**Посчитаем долю пропусков в датафрейме investment**
```
pd.DataFrame(round(investment.isna().mean()*100, 2)).sort_values(by=0, ascending=False).style.background_gradient('coolwarm')
```
![Пропуски_investment](https://github.com/Olga-Elkhova/Startup-research/blob/main/Пропуски_investment.png)
В датафрейме `company_and_rounds` пропуски связаны, скорее всего, с присоединением другой таблицы (это видно по названиям столбцов). Также пропуски в датах закрытия компании, вехах финансирования логичны, если компания еще не закрыта или прошла веху финансирования.
 
Пропуски в `acquisition` могут быть связаны с отсутствием этих данных у заказчика. 

Пропуски в `education`, `degrees` и `people` могут быть связаны с с тем что компании не полностью указывают информацию о сотрудниках.

Пропуски в `fund` также, скорее всего, связаны с неполной информацией у заказчика.
 
Пропусков в `investment` нет.

Во всех датафреймах, кроме `investment`, содержится значительное количество пропусков, от 25% до 98%. Удаление такого количества информации приведет к искажению результатов при анализе. При этом информацию о раундах финансирования, раундах инвестирования и денежных суммах можно считать достаточной для анализа. Оставим пропуски без изменений.

Помимо этого, некоторые поля могут быть опциональными и поэтому их не все компании заполнили

## Шаг 2. Предобработка данных, предварительное исследование

### 2.1 Раунды финансирования по годам
 
**Выведем сводную таблицу по годам с типичным размером средств для одного раунда и общим количеством раундов в год**
```
funding_years = company_and_rounds.groupby('funded_year').agg({'raised_amount':'median', 'funding_rounds':'sum'})
```
**Оставим года в которых количество раундов больше 50**
```
funding_years_50 = funding_years.loc[funding_years['funding_rounds'] >= 50]
display(funding_years_50)
```
**Построим график для визуализации финансирования по годам**
```
funding_years_50['raised_amount'].plot.line()
plt.title('Типичный размер средств для одного раунда по годам')
plt.xlabel('')
plt.ylabel('Млн.руб.')
plt.figure(figsize=(12, 6))
plt.show()
```
![Визуализация_финансирования_по%20годам](https://github.com/Olga-Elkhova/Startup-research/blob/main/Визуализация_финансирования_по%20годам.png)
- В 2005 году типичный размер собранных в рамках одного раунда средств был максимален и составил 5,5 млн.руб.
- До 2005 года наблюдался неравномерный рост финансирования в одном раунде, а после 2005 года равномерный спад до 1,0 млн.руб. в 2012 году.
- В 2013 году сбор средств увеличился до 1,2 млн.руб

- Количество раундов непрерывно росло до максимального значения 24549 в 2012 году
- В 2013 году количество раундов снизилось до 23978

### 2.2 Люди и их образование

Заказчик хочет понять, зависит ли полнота сведений о сотрудниках (например, об их образовании) от размера компаний.

**Соединим датафреймы people и education для анализа компаний**
```
people_education = people.merge(education, left_on='id', right_on='person_id', how='left')
```
**Выведем несколько строк объединенного датафрейма**
```
display(people_education.head(20))
```
**Посчитаем долю сотрудников без инфрмации об образовании по всем данным**
```
round(1-people_education['instituition'].nunique() / len(people_education['instituition']),2)
```
**Посчитаем долю сотрудников без инфрмации об образовании по компаниям**
```
people_education['education_share'] = round((1 - people_education.groupby('company_id')['instituition'].transform('nunique')
                                          / people_education.groupby('company_id')['instituition'].transform('size')),2)
```
**Посчитаем количество сотрудников по компаниям**
```
people_education['people_count'] = people_education.groupby('company_id')['person_id'].nunique()
```
**Назначим категории компаниям** 

Закон устанавливает рамочные критерии для отнесения предприятий к малым и средним. Первый критерий - численность работников, второй - выручка предприятия. 
 
К микропредприятиям относятся организации, в которых число сотрудников не превышает 15, к малым - с штатом от 16 до 100 человек, к средним - с числом сотрудников до 250 человек.

На основе наших данных разделим компании на категории по количеству сотрудников.

**Сгруппируем компании по количеству сотрудников**
```
people_education['category'] = pd.cut(people_education['people_count'], bins=[0, 1, 15, 100, 250, 1000, 100000], labels=["Один сотрудник" ,"Микро", "Малая", "Средняя", "Крупная", "Очень крупная"])
```
**Построим график столбчатой диаграммы по категориям**
```
people_education.groupby('category')['education_share'].mean().plot(kind='bar',
               title=f'Распределение доли сотрудников без информации об образовании',
               legend=True,
               ylabel='Доля сотрудников',
               xlabel='Категория компании',
               rot=0,
               figsize=(8, 4))
plt.grid()
plt.show()
```

На диаграмме видна зависимость пропусков информации об образовании и размеров компании.

Возможно, в малых компаниях HR-процессы менее структурированы и могут быть пропуски в данных о сотрудниках.

В средних и крупных компаниях пропусков нет. Возможно, выше вероятность полной информации об образовании из-за налаженых HR-процессов.

**Попробуем дополнить датафрейм `people_education` информацией из таблицы `degrees`.**

Объединить таблицы можно по столбцу идентификатору сотрудника - 'person_id' и 'object_id'. Столбец 'person_id' содержит буквенный индекс перед номером id и имеет тип данных object. Перед объединением нужно убрать буквенный индекс и изменить тип данных.

**Уберем буквы из id сотрудника в столбце 'object_id'**
```
degrees['object_id'] = degrees['object_id'].str.replace('p:', '')
```
**Меняем тип данных**
```
degrees['object_id'] = degrees['object_id'].astype('int64')
```
**Проверим корректность исправлений**
```
degrees.head()
degrees.info()
```
Название и тип данных скорректированы. Можно объединять таблицы

**Присоединим таблицу degrees**
```
people_education_degrees = people_education.merge(degrees, left_on='person_id', right_on='object_id', how='left')
```
**Выведем несколько строк объединенного датафрейма**
```
display(people_education_degrees.head(20))
```
**Выведем названия типа образования сотрудников**
```
people_education_degrees['degree_type'].unique()
```
**Выведем названия специальностей сотрудников**
```
people_education_degrees['subject'].unique()
```
Похоже, что информация из таблицы `degrees` не поможет заполнить пропуски в информации об образовании, но дополнит существующую информацию. 

Теперь данные дополнены информацией о типе образования и специальностях сотрудников. При необходимости, можно использовать эту информацию для анализа. 

### 2.3 Объединять или не объединять — вот в чём вопрос

Некоторые названия столбцов встречаются в датасетах чаще других. В результате предварительной проверки датасетов было выяснено, 
что столбец `company_id` подходит для объединения данных, так как большая часть значений встречается в разных датасетах не один, а несколько раз.
Нужно проверить, подходит ли для объединения данных столбец `network_username`, который встречается в нескольких датасетах.

**Выведем уникальные значения, чтобы оценить столбцы 'network_username'**
```
company_and_rounds['network_username'].unique()
people['network_username'].unique()
fund['network_username'].unique()
```
Столбец `network_username` встречается в таблицах `people`, `company_and_rounds` и `fund` и содержит информацию о никах сотрудника, компании и фонда в соцсетях. Потенциально сотрудник может указать в нике компанию. Но на этапе знакомства с данными видно, что ник чаще всего содержит имя сотрудника, название компании или фонда, так что столбец `network_username` не подходит для объединения данных.

### 2.4 Проблемный датасет и причина возникновения пропусков

Во время собственного анализа данных у заказчика больше всего вопросов возникло к датасету `company_and_rounds.csv`. В нём много пропусков как раз в информации о раундах, которая заказчику важна. Хотя информация об общем объёме финансирования по раундам присутствует в других датасетах, заказчик считает данные `company_and_rounds.csv` о размере средств наиболее верными.

По гипотезе заказчика данные по компаниям из этой таблицы раньше хранились иначе, более удобным для исследования образом.

Судя по названию столбцов и информации от заказчика, таблица `company_and_rounds` составлена из двух таблиц. Скорее всего таблица с информацией о компаниях была дополнена таблицей с этапами финансирования. Есть два столбца с одинаковым назавнием `company_ID` и `company_id` и два столбца с суммой финансирования `funding_total` и `raised_amount`. В столбце `raised_amount` суммы знаительно меньше, похоже, они отражают сумму одного этапа. В столбце `funding_total` скорее всего содержится вся сумма финансирования. Столбцы, расположенные после `funding_round_id` имеют много пропусков.

**Разделим датафрейм на два. Один с с информацией о компаниях, второй с этапами финансирования.**
```
company_and_rounds.head()
```
**Создадим датафрейм с информацией о компаниях**
```
company = company_and_rounds.drop(columns=['funding_round_id', 'company_id', 'funded_at', 'funding_round_type', 'raised_amount',
                                                           'pre_money_valuation', 'participants', 'is_first_round',
                                                           'is_last_round', 'founded_year', 'closed_year', 'funded_year'])
```
**Удалим дубликаты в таблице company**
```
company = company.drop_duplicates()
```
**Выведем пропуски в столбце id, если они есть, так как  пропуски помешают изменить тип столбца**
```
company[company['id'].isna()]
```
Пропуск содержится в строке 217472, кроме того в этой строке нет данных ни по одному столбцу. Можно удалить эту строку

**Удалим строку с пропуском в id**
```
company = company.dropna(subset=['id'])
```
**Отсортируем по id**
```
company = company.sort_values(by='id')
```
**Приведем столбец id к целочисленному типу**
```
company['id'] = company['id'].astype('int64')
```
**Посмотрим на типы данных**
```
company.info()
```
**Сбросим старый индекс**
```
company.reset_index(drop=True)
```
**Выведем несколько строк итогового датасета**
```
company.head()
```
**Без пропусков** в датафрейме `company` содержится информация о
- name - названии компании
- status — статус компании
- investment_rounds — число инвестиционных раундов
- funding_rounds — число раундов финансирования
- funding_total — сумма финансирования
- milestones — вехи финансирования

эти данные полны и позволят анализировать финансирование компаний

**Пропуски** остались в столбцах 
- category_code — категория области деятельности компании
- founded_at — дата инвестирования
- closed_at — дата закрытия компании
- domain  — официальный сайт компании
- network_username — ник компании в сети
- country_code — код страны компании

эти данные не так важны для анализа финансирования компаний, поэтому их можно оставить без изменений

**Сделаем тоже самое для нового датафрейма `rounds`**

**Создадим датафрейм с информацией о раундах**
```
rounds = company_and_rounds[['funding_round_id', 'company_id', 'funded_at', 'funding_round_type', 'raised_amount',
                                                           'pre_money_valuation', 'participants', 'is_first_round',
                                                           'is_last_round', 'founded_year', 'closed_year', 'funded_year']]
rounds.info()
```
**Удалим дубликаты в таблице rounds**
```
rounds = rounds.drop_duplicates()
```
**Выведем пропуски в столбце id, если они есть, так как пропуски помешают изменить тип столбца**
```
rounds[rounds['funding_round_id'].isna()]
```
Столбец `funding_round_id` содержит 201 строку с пропусками, а также пропуски почти во всех ячейках. Так как без `funding_round_id` эта информация неприменима для анализа , можно удалить эти строки

**Удалим строку с пропусками в funding_round_id```
```
rounds = rounds.dropna(subset=['funding_round_id'])
```
**Приведем столбцы с id к целочисленному типу**
```
rounds['funding_round_id'] = rounds['funding_round_id'].astype('int64')
rounds['company_id'] = rounds['company_id'].astype('int64')
```
**Отсортируем по id**
```
rounds = rounds.sort_values(by='funding_round_id')
```
**Сбросим старый индекс**
```
rounds.reset_index(drop=True)
rounds.head()
```
**Проверим тип данных**
```
rounds.info()
```

**Без пропусков** в датафрейме `rounds` содержится информация о     
- company_id  — идентификатор компании.      
- funded_at — дата финансирования.  
- funding_round_type  — тип финансирования.      
- raised_amount  — сумма финансирования.        
- pre_money_valuation — предварительная денежная оценка.
- participants  — число участников.           
- is_first_round — является ли раунд первым.          
- is_last_round — является раунд последним.       
 
эти данные полны и позволят анализировать финансирование компаний
 
**Пропуски** остались в столбцах 
- founded_year   — дата инвестирования.  
- closed_year   — дата закрытия компании.       
- funded_year   — дата финансирования. 
 
эти данные не так важны для анализа финансирования компаний, поэтому их можно оставить без изменений


## Шаг 3. Исследовательский анализ объединённых таблиц
 
### 3.1 Объединение данных

Объединим данные для ответа на вопросы заказчика, которые касаются интересующих его компаний.
 
В качестве основы для объединённой таблицы возьмем данные из обработанного датасета `company_and_rounds.csv` — выберем только те компании, у которых указаны значения `funding_rounds` или `investment_rounds` больше нуля, или те, у которых в колонке `status` указано `acquired`.

Далее работаем только с этими данными.

**Создадим датафрейм со значениями раундов финансирования и инвестирования больше нуля и статусом компании acquired**
```
company_filtered = company[(company['funding_rounds']>0) | (company['investment_rounds']>0) | (company['status']=='acquired')]
company_filtered.info()
company_filtered.shape
```
### 3.2. Анализ выбросов
 
Заказчика интересует обычный для рассматриваемого периода размер средств, который предоставлялся компаниям.

**По предобработанному столбцу `funding_total` графическим способом оценим, какой размер общего финансирования для одной компании будет типичным, а какой — выбивающимся.**
**Разброс данных по столбцу funding_total**
```
company_filtered['funding_total'].describe()
```
По разбросу значений видно, что распределение `funding_total` сильно асимметрично:
 
- min = 0, max = 5.7 млрд.
- среднее = 10,1 млн.
- медиана = 600 тыс.
- 75% квантиль = 5.65 млн.
 
Среднее значительно больше медианы, что говорит о наличии выбросов. Гистограмма или boxplot на линейной шкале будет смещена из-за очень больших выбросов. Также сами значения и их разброс очень большие, что сделает нечитаемой визуализацию.

В данном случае лучше использовать логарифмическую шкалу.
 
Так как заказчика интересует стартапы получившие финансирование, отфильтруем значения `funding_total` равные 0.

**Отфильтруем значения funding_total равные 0**
```
company_filtered = company_filtered[company_filtered['funding_total'] > 0]
```
**Разброс данных по столбцу funding_total со значениями больше 0**
```
company_filtered['funding_total'].describe()
```
**Построим гистограмму, чтобы посмотреть как распределяются размеры финансирования**
```
funding_log = np.log10(company_filtered['funding_total'] + 1)
plt.figure(figsize=(10, 6))
sns.histplot(funding_log, bins=100, kde=True, color='skyblue')
plt.title('Распределение размеров финансирования (логарифмическая шкала)')
plt.xlabel('Размеры финансирования (log10)')
plt.ylabel('Частота')
plt.show()

# Построим boxplot для оценки данных
plt.figure(figsize=(10, 2))
sns.boxplot(x=np.log10(company_filtered['funding_total'] + 1), color='skyblue')
plt.title('Boxplot финансирования (логарифмическая шкала)')
plt.xlabel('log10(funding_total)')
plt.grid()
plt.show()
```
Теперь значения распределились так:
 
- min = 291 , max = 5.7 млрд.
- среднее = 14,8 млн.
- медиана = 2,56 млн.
- 75% квантиль = 11 млн.
 
Среднее и медиана сильно отличаются. За типичное финансирование компании лучше взять медиану значений 2,56 млн, чтобы избежать влияния выбросов.
 
Судя по боксплоту нетипичным, выбивающимся финансированием можно считать значения `funding_total` до 3,7 млн. и свыше 9 млн.

### 3.3 Куплены забесплатно?
 
- Исследуем компании, которые были проданы за ноль или за один доллар, и при этом известно, что у них был ненулевой общий объём финансирования.
- Рассчитаем аналитически верхнюю и нижнюю границу выбросов для столбца `funding_total` и посмотрим, каким процентилям границы соответствуют.
- Исследуем стартапы с ненулевым финансированием, но проданым за 0 или 1 доллар.
**Объединим датафреймы с информацией о покупке компаний и с информацией о финансировании, где общая сумма финансирования больше 0**
```
company_amount = acquisition.merge(company_filtered, left_on='acquired_company_id', right_on='id', how='left')
```
**Выберем стартапы проданные за 0 или за 1 доллар**
```
company_amount_zero = company_amount[(company_amount['price_amount'] == 0) | (company_amount['price_amount'] <=1)]
```
**Посмотрим информацию по получившемуся срезу**
```
company_amount_zero.info()
```
Всего таких стартапов, купленных за 0 или до 1 доллара 6934.

**Посмотрим информацию по этим данным**
```
company_amount_zero['funding_total'].describe()
```
**Построим гистограмму, чтобы посмотреть как распределяются размеры финансирования для дешевых стартапов**
```
funding_log = np.log10(company_amount_zero['funding_total'] + 1)
plt.figure(figsize=(10, 6))
sns.histplot(funding_log, bins=100, kde=True, color='skyblue')
plt.title('Распределение размеров финансирования дешевых стартапов (логарифмическая шкала)')
plt.xlabel('Размеры финансирования (log10)')
plt.ylabel('Частота')
plt.show()

# Построим boxplot для оценки данных
plt.figure(figsize=(10, 2))

sns.boxplot(x=np.log10(company_amount_zero['funding_total'] + 1), color='skyblue')

plt.title('Boxplot финансирования дешевых стартапов (логарифмическая шкала)')
plt.xlabel('log10(funding_total)')
plt.grid()
plt.show()
```

Значения финансирования дешевых стартапов распределились так:
 
- min = 3750 , max = 5,7 млрд.
- среднее = 18,15 млн.
- медиана = 6 млн.
- 75% квантиль = 15,5 млн.

Среднее и медиана сильно отличаются. За типичное финансирование компании лучше взять медиану значений, чтобы избежать влияния выбросов.

Нетипичным, выбивающимся финансированием можно считать значения `funding_total` до 5 млн. и свыше 8,5 млн.

**Рассчитаем аналитически верхнюю и нижнюю границу выбросов для столбца funding_total**
```
# Посчитаем первый и третий квартили (25% и 75%)**
Q1 = company_amount_zero['funding_total'].quantile(0.25)
Q3 = company_amount_zero['funding_total'].quantile(0.75) 

# Посчитаем межквартильный размах
IQR = Q3 - Q1 
# Посчитаем нижнюю и верхнюю границы выбросов
lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

display(f"Нижняя граница: {lower_bound}")
display(f"Верхняя граница: {upper_bound}")
```

**Нижняя граница: -18250000.0**
**Верхняя граница: 35750000.0**

Нижняя граница получилась отрицательной. Скорее всего это вызванно ассиметричностью данных, большим количеством маленьких значений и наличием выбросов. Так как финансирование не может быть отрицательным, то за нижнюю границу можно принять ноль.

**Посчитаем каким процентилям соответствуют граицы выбросов**
```
lower_percentile = (company_amount_zero['funding_total'] < lower_bound).mean()*100
upper_percentile = (company_amount_zero['funding_total'] > upper_bound).mean()*100

display(f"Нижняя граница выбросов - {lower_percentile:.2f}%")
display(f"Верхняя граница выбросов - {100 - upper_percentile:.2f}%")
```
**Границы выбросов соответствуют 0% и 76,67%**

### 3.4 Цены стартапов по категориям

Категории стартапов с наибольшими ценами и значительным разбросом цен могут быть наиболее привлекательными для крупных инвесторов, которые готовы к высоким рискам ради потенциально больших доходов. 
Среди категорий стартапов выделим категории стартапов, характеризующиеся:
 
- наибольшими ценами;
- и наибольшим разбросом цен за стартап.
 
**Для разбиения на категории сначала выведем размах данных по ценам стартапов**
```
acquisition['price_amount'].describe()
```
Судя по разбросу значений, в данных о ценах на стартапы присутствует много нулевых значений. Поскольку нам надо проанализировать стартапы с наибольшими ценами, отфильтруем нулевые значения

**Создадим датафрейм без нулевых значений**
```
acquisition_notnull = acquisition[(acquisition['price_amount']>0) & (acquisition['price_amount']<2.600000e+12)]
```
**Выведем размах данных по ценам стартапов без нулевых значений**
```
acquisition_notnull['price_amount'].describe()
```
**Построим гистограмму, чтобы посмотреть как распределяются цены стартапов**
```
funding_log = np.log10(acquisition_notnull['price_amount'] + 1)
plt.figure(figsize=(10, 6))
sns.histplot(funding_log, bins=100, kde=True, color='skyblue')

plt.title('Распределение размеров цен стартапов (логарифмическая шкала)')
plt.xlabel('Цены стартапов (log10)')
plt.ylabel('Частота')

plt.show()
```
**Построим boxplot для оценки данных**
```
plt.figure(figsize=(10, 2))
sns.boxplot(x=np.log10(acquisition_notnull['price_amount'] + 1), color='skyblue')

plt.title('Boxplot стоимости стартапов (логарифмическая шкала)')
plt.xlabel('log10(funding_total)')
plt.grid()
plt.show()
```
Поскольку у нас нет явных критериев от заказчика для разбиения по ценам стартапов, то примем такую категоризацию:
- Малые < 1 млн,
- Средние 1 млн - 10 млн,
- Крупные 10 млн - 100 млн,
- Очень крупные 100M - 10 млрд,
- Гиганты > 10 млрд"

**Разделим цены стартапов по категориям:**
```
bins = [-float('inf'), 1_000_000, 10_000_000, 100_000_000, 10_000_000_000, float('inf')]
labels = ["Малые", "Средние", "Крупные", "Очень крупные", "Гиганты"]
acquisition_notnull = acquisition_notnull.copy()
acquisition_notnull['category_amount'] = pd.cut(acquisition_notnull['price_amount'], bins=bins, labels=labels)
# Выведем несколько строк датафрейма с новым столбцом категорий
acquisition_notnull.head()
```
**Посчитаем среднюю цену по категориям**
```
category_amount_mean = acquisition_notnull.groupby('category_amount')['price_amount'].mean().sort_values(ascending=False)
category_amount_mean
```
**Посмотрим для наглядности цены на столбчатой диаграмме**
```
category_amount_mean.plot.bar(legend=True,
                title='Средние цены на стартапы по категориям',  
                ylabel='Средние цены',  
                xlabel='',
                color='skyblue',
                edgecolor='black',                                                                   
                rot=0)
sns.set_style("whitegrid")
plt.figure(figsize=(16, 16))
plt.show()
```
Наибольшие средние цены за стартапы в категории Гиганты.

**Разделим цены стартапов c нулевыми ценами по категориям:**
```
bins = [-float('inf'), 1_000_000, 10_000_000, 100_000_000, 10_000_000_000, float('inf')]
labels = ["Малые", "Средние", "Крупные", "Очень крупные", "Гиганты"]
#acquisition = acquisition.copy()
acquisition['category_amount'] = pd.cut(acquisition['price_amount'], bins=bins, labels=labels)
```
**Посчитаем разброс цен как стандартное отклонение по категориям учитывая нулевые значения**
```
category_amount_std = acquisition.groupby('category_amount')['price_amount'].std().sort_values(ascending=False)
category_amount_std
```

**Посмотрим для наглядности разброс цен на столбчатой диаграмме**
```
category_amount_std.plot.bar(legend=True,
                title='Разброс цен на стартапы по категориям',  
                ylabel='Разброс цен',  
                xlabel='',
                color='skyblue',
                edgecolor='black',                                                                   
                rot=0)
sns.set_style("whitegrid")
plt.figure(figsize=(16, 16))
plt.show()
```
Наибольший разброс цен в категории  Гиганты.

Наибольший интерес по цене представляют крупные компании, но при этом они же связаны с большими рисками, так как имеют больший разброс цен.

Tаким образом, высокий разброс цен может говорить о том, что инвестировать в данную категорию стартапов рисковано, но с другой стороны в случае успешного выбора есть возможность получить более высокий доход чем в случае инвестирования в менее рискованную категорию стартапов.

### 3.5 Сколько раундов продержится стартап перед покупкой

- Необходимо проанализировать столбец `funding_rounds`. Исследуем значения столбца. Заказчика интересует типичное значение количества раундов для каждого возможного статуса стартапа.

- Построим график, который отображает, сколько в среднем раундов финансирования проходило для стартапов из каждой группы.

**Посмотрим на значения в стобце funding_rounds**
```
company_filtered['funding_rounds'].describe()
```
Так как максимальное значение сильно выделяется и медиана значительно меньше среднего, значения в данных неравномерны. Поэтому за типичное среднее количество раундов лучше взять значение медианы.

**Посчитаем типичное значение числа раундов финансирования по статусам**
```
company_filtered.groupby('status')['funding_rounds'].median()
```
**Выведем типичное значение числа раундов финансирования по статусам на диаграмме**
```
company_filtered.groupby('status')['funding_rounds'].median().sort_values(ascending=False).plot.bar(legend=True,
                title='Среднее число раундов финансирования по статусам',  
                ylabel='Среднее число раундов',  
                xlabel='Статус компании',
                color='skyblue',
                edgecolor='black',                                                                   
                rot=0)
sns.set_style("whitegrid")
plt.figure(figsize=(16, 16))
plt.show()
```
До стадии IPO доходят только самые успешные стартапы и соответственно число раундов финансирования, как правило, больше чем у остальных стадий развития стартапов.
Наибольшее среднее количество раундов в категории купленных компаний acquired и со статусом ipo - вышедших на фондовый рынок.

## Шаг 4. Итоговый вывод и рекомендации

**В ходе проекта были проведены**
 
- Сбор и подготовка данных: Данные были очищены от пропущенных значений и дубликатов и приведены к удобному для анализа формату, проведены разделение либо объединение таблиц, необходимых для анализа.
 
- Анализ данных: Были исследованы основные статистические характеристики, проведена визуализация распределений и выявлены возможные закономерности.

- Оценка результатов: Проведен анализ метрик и проверка гипотез.

**Выводы:**
 
Полученные результаты подтвердили гипотезу о том полнота сведений о сотрудниках (например, об их образовании) зависит от размера компаний. Чем меньше компания, тем меньше информации о сотрудниках.
 
В ходе анализа определен типичный общий размер финансирования одной компании в 2,56 млн

Выявлены компании которые были проданы за ноль или за один доллар, и при этом известно, что у них был ненулевой общий объём финансирования.

Компании стартапов разбиты на категории:
- Малые < 1 млн,
- Средние 1 млн - 10 млн,
- Крупные 10 млн - 100 млн,
- Очень крупные 100M - 1 млрд,
- Гиганты > 1 млрд"
 
Проведен анализ типичных цен на стартапы и наибольший разброс цен за стартап.  Наибольший интерес по цене представляют крупные компании - категория Гиганты, но при этом они же связаны с большими рисками, так как имеют больший разброс цен.
 
Проанализированы данные о количестве раундов финансирования стартапов по группам:
 
- acquired 
- closed
- ipo
- operating

В среднем в каждой группе проходит от 1 до 2 раундов. Наибольшее среднее количество раундов финансирования проходят купленные компание и компании со статусом ipo - вышедшие на фондовый рынок.
